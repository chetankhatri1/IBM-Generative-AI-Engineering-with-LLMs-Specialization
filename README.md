Course 1: Generative AI and LLMs: Architecture and Data Preparation
In this course, you will explore the significance of generative AI in various domains. You will differentiate between generative AI models and learn how LLMs are used to build NLP-based applications. Additionally, you will learn about the libraries and tools used in developing these applications. Finally, you will learn to prepare data to train LLMs by implementing tokenization and creating NLP data loaders. 

Course content 

The Generative AI and LLMs: Architecture and Data Preparation course includes the following modules:

Module 1: Generative AI Architecture

Module 2: Data Preparation for LLMs 

Course 2: Generative AI Foundational Models for NLP & Language Understanding
This course will introduce you to the various aspects of NLP and AI model development. You will learn about the fundamentals of language understanding, including converting words to features. You will also learn about various models such as N-Gram, Word2Vec, and sequence-to-sequence models and the metrics to evaluate the quality of the generated text. Finally, you will implement document classification, build, and train a simple language model, integrate Word2Vec, and develop a sequence-to-sequence model.

Course content 

The Gen AI Foundational Models for NLP & Language Understanding course includes the following modules: 

Module 1: Fundamentals of Language Understanding

Module 2: Word2Vec and Sequence-to-Sequence Models

Course 3: Generative AI-Language Modeling with Transformers
This course covers the fundamental concepts of transformer-based models for NLP. You’ll explore the significance of positional encoding and word embedding, understand attention mechanisms and their role in capturing context and dependencies, and learn about multi-head attention. You’ll learn how to apply transformer-based models for text classification, specifically focusing on the encoder component. You will also learn about decoder-based models, such as GPT, and encoder-based models, such as BERT, and use them for language translation.

Course content 

The Generative AI-Language Modeling with Transformers course includes the following modules: 

Module 1: Fundamental Concepts of Transformer Architecture

Module 2: Advanced Concepts of Transformer Architecture

Course 4: Generative AI Engineering and Fine-Tuning Transformers
In this course, you’ll explore the concepts of PyTorch and Hugging Face and their differences. You’ll also understand how to use pre-trained transformers for language tasks and fine-tune them for special tasks. Further, you’ll fine-tune generative AI models using PyTorch and Hugging Face. Finally, you’ll learn parameter-efficient fine-tuning (PEFT), low-rank adaptation (LoRA), quantized low-rank adaptation (QloRA), model quantization, and prompting in transformers.

Course content 

The Generative AI Engineering and Fine-Tuning Transformers course includes the following modules: 

Module 1: Transformers and Fine-Tuning

Module 2: Parameter Efficient Fine-Tuning (PEFT)

Course 5: Generative AI Advanced Fine-Tuning for LLMs
In this course, you’ll explore the basics of instruction-tuning with Hugging Face, reward modeling, and how to train a reward model. You’ll also learn proximal policy optimization (PPO) with Hugging Face, large language models (LLMs) as policies, and reinforcement learning from human feedback (RLHF). This course will further delve into direct performance optimization (DPO) with hugging Face using the partition function.

Course content 

The Generative AI Advanced Fine-Tuning for LLMs course includes the following modules: 

Module 1: Different Approaches to Fine-Tuning

Module 2: Fine-Tuning Causal LLMs with Human Feedback and Direct Preference

Course 6: Fundamentals of AI Agents Using RAG and LangChain
In this course, you’ll learn to generate responses using retrieval-augmented generation (RAG), and how RAG involves encoding prompts into vectors, sorting them, and retrieving related information. You’ll also explore RAG, encoder, and Facebook AI similarity search (FAISS). Further, you’ll explore prompt engineering and in-context learning, where tasks are provided to the model as a prompt. In advanced methods of prompt engineering, you’ll learn zero-shot prompts, few-shot prompts, chain-of-thought (CoT) prompting, and self-consistency. Finally, you’ll explore LangChain and its components, such as documents, chains, and agents. 

Course content

The Fundamentals of AI Agents Using RAG and LangChain course includes the following modules: 

Module 1: RAG Framework

Module 2: Prompt Engineering and LangChain

Course 7: Project: Generative AI Applications with RAG and LangChain
This course will allow you to apply your acquired knowledge and skills to a capstone project. You’ll learn about document loaders from LangChain and then use that knowledge to load your document from various sources. You’ll also have the option to use Hugging Face to predict the document. Then, you’ll learn about text-splitting strategies and apply them to enhance model responsiveness. You’ll then use Watsonx to embed documents, a vector database to store document embeddings, and LangChain to develop a retriever to fetch documents. Further, you’ll implement RAG to improve retrieval, create a QA bot, and set up a simple Gradio interface to interact with your models. Finally, you will construct a QA bot to answer questions from loaded documents.

Course content 

The Project: Generative AI Applications with RAG and LangChain course includes the following modules: 

Module 1: Document Loader Using LangChain

Module 2: RAG Using LangChain

Module 3: Create a QA Bot to Read Your Document

Learning resources

The courses in this specialization offer various learning assets, such as videos, readings, practice, graded quizzes, and a Capstone project.

Ungraded quizzes, including multiple-choice questions with single or multiple correct answers, are provided in each lesson.

Graded quizzes, including scenario-based, multiple-choice questions with single or multiple correct answers, are included in each course.

One specialization-wide graded assessment is provided, including multiple-choice questions with single or multiple correct answers.

Hands-on project: A peer-graded project at the end of the specialization that aims to test the learner’s ability to apply most of the knowledge and skills developed in the course.
